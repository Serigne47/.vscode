# utils/vectorize_documents.py
"""
Script pour vectoriser les documents extraits par Enhanced Chunker
"""
import logging
import json
from pathlib import Path
from typing import List, Dict, Any

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from aoagentc.utils.arch0.enhanced_chunker1 import EnhancedChunker
from aoagentc.utils.arch0.vectorstore1 import AOVectorStore, get_vectorstore, index_extracted_elements

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def vectorize_from_json(
    json_file: Path,
    collection_name: str = "ao_documents",
    clear_existing: bool = False
) -> AOVectorStore:
    """
    Vectorise √† partir d'un fichier JSON d'√©l√©ments extraits
    
    Args:
        json_file: Fichier JSON des √©l√©ments extraits
        collection_name: Nom de la collection ChromaDB
        clear_existing: Supprimer la collection existante
        
    Returns:
        Instance du vectorstore
    """
    logger.info(f"üìÑ Chargement de {json_file}")
    
    # Charger les √©l√©ments extraits
    with open(json_file, 'r', encoding='utf-8') as f:
        extracted_elements = json.load(f)
    
    logger.info(f"‚úÖ {len(extracted_elements)} √©l√©ments charg√©s")
    
    # Initialiser le vectorstore
    vectorstore = get_vectorstore(collection_name=collection_name)
    
    # Supprimer la collection existante si demand√©
    if clear_existing:
        logger.info("üóëÔ∏è Suppression de la collection existante...")
        vectorstore.delete_collection()
        vectorstore = get_vectorstore(collection_name=collection_name)
    
    # Indexer les √©l√©ments
    vectorstore = index_extracted_elements(extracted_elements, vectorstore)
    
    return vectorstore

def vectorize_from_folder(
    folder_path: Path,
    collection_name: str = "ao_documents",
    clear_existing: bool = False,
    save_extracted: bool = True
) -> AOVectorStore:
    """
    Extraction et vectorisation compl√®te depuis un dossier
    
    Args:
        folder_path: Dossier contenant les documents
        collection_name: Nom de la collection ChromaDB
        clear_existing: Supprimer la collection existante
        save_extracted: Sauvegarder les √©l√©ments extraits en JSON
        
    Returns:
        Instance du vectorstore
    """
    logger.info(f"üöÄ Vectorisation compl√®te depuis {folder_path}")
    
    # √âtape 1: Extraction avec Enhanced Chunker
    logger.info("üìÑ Extraction des documents...")
    chunker = EnhancedChunker()
    extracted_elements = chunker.process_folder(folder_path)
    
    # Sauvegarder les √©l√©ments extraits si demand√©
    if save_extracted:
        output_file = Path("extracted_elements.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(extracted_elements, f, indent=2, ensure_ascii=False, default=str)
        logger.info(f"üíæ √âl√©ments sauvegard√©s dans {output_file}")
    
    # √âtape 2: Vectorisation
    logger.info("üîÑ Vectorisation...")
    vectorstore = get_vectorstore(collection_name=collection_name)
    
    if clear_existing:
        logger.info("üóëÔ∏è Suppression de la collection existante...")
        vectorstore.delete_collection()
        vectorstore = get_vectorstore(collection_name=collection_name)
    
    # Indexer les √©l√©ments
    vectorstore = index_extracted_elements(extracted_elements, vectorstore)
    
    return vectorstore

def test_vectorstore(vectorstore: AOVectorStore):
    """
    Teste les fonctionnalit√©s du vectorstore
    """
    logger.info("üß™ Test du vectorstore...")
    
    # Stats g√©n√©rales
    stats = vectorstore.get_collection_stats()
    logger.info(f"üìä Statistiques: {stats}")
    
    # Tests de recherche par domaine
    test_queries = {
        "financial": "price tariff cost budget payment",
        "legal": "responsibility clause insurance penalty",
        "operational": "transport maritime air volume TEU",
        "timeline": "deadline deadline delay date planning"
    }
    
    for domain, query in test_queries.items():
        logger.info(f"\nüîç Test recherche {domain}: '{query}'")
        
        # Recherche standard
        results = vectorstore.similarity_search(query, k=3)
        logger.info(f"   Recherche standard: {len(results)} r√©sultats")
        
        # Recherche par domaine
        domain_results = vectorstore.search_by_domain(query, domain, k=3)
        logger.info(f"   Recherche {domain}: {len(domain_results)} r√©sultats")
        
        # Afficher le premier r√©sultat
        if domain_results:
            first_result = domain_results[0]
            logger.info(f"   Premier r√©sultat: {first_result.metadata.get('type', 'N/A')} "
                       f"(priorit√© {domain}: {first_result.metadata.get(f'priority_{domain}', 0):.2f})")
            logger.info(f"   Texte: {first_result.page_content[:100]}...")

def main():
    """
    Script principal de vectorisation
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Vectorisation des documents AO")
    parser.add_argument("--source", type=str, required=True,
                       help="Chemin vers le dossier de documents ou fichier JSON")
    parser.add_argument("--collection", type=str, default="ao_documents",
                       help="Nom de la collection ChromaDB")
    parser.add_argument("--clear", action="store_true",
                       help="Supprimer la collection existante")
    parser.add_argument("--test", action="store_true",
                       help="Tester le vectorstore apr√®s cr√©ation")
    
    args = parser.parse_args()
    
    source_path = Path(args.source)
    
    try:
        if source_path.suffix == '.json':
            # Vectorisation depuis JSON
            vectorstore = vectorize_from_json(
                json_file=source_path,
                collection_name=args.collection,
                clear_existing=args.clear
            )
        elif source_path.is_dir():
            # Vectorisation depuis dossier
            vectorstore = vectorize_from_folder(
                folder_path=source_path,
                collection_name=args.collection,
                clear_existing=args.clear
            )
        else:
            raise ValueError(f"Source invalide: {source_path}")
        
        # Test si demand√©
        if args.test:
            test_vectorstore(vectorstore)
        
        logger.info("üéâ Vectorisation termin√©e avec succ√®s!")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur: {e}")
        raise

if __name__ == "__main__":
    main()